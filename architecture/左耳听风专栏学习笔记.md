
[TOC]

## 21 分布式系统的冰与火
使用分布式系统的原因：
- 增大系统容量
- 加强系统可用

分布式系统优势：
- 模块化，所以系统模块重用度更高；
- 软件服务模块被拆分，开发和发布速度可以并行而变得更快
- 系统扩展性更高
- 团队协作流程也会得到改善
- ……
  
分布式系统劣势：
- 架构设计变得复杂
- 部署复杂
- 吞吐量会变大，但是响应时间会变长
- 架构复杂导致学习曲线变大。
- 测试和查错的复杂度增大。
- 技术多元化，这会带来维护和运维的复杂度。
- 管理分布式系统中的服务和调度变得困难和复杂。

## 22 从亚马逊的实践，谈分布式系统的难点
亚马逊分布式服务实践总结：
- 分布式服务的架构需要分布式的团队架构
- 分布式服务查错不容易
  - 一旦出现问题，所有相关人士都要在线
- 没有专职的测试人员，也没有专职的运维人员，开发人员做所有的事情
- 运维优先，崇尚简化和自动化
- 内部服务和外部服务一致

### 分布式系统中需要注意的问题
#### 问题一：异构系统的不标准问题
表现在：
- 软件和应用不标准
- 通讯协议不标准。
- 数据格式不标准。
- 开发和运维的过程和方法不标准。

#### 问题二：系统架构中的服务依赖性问题
- 如果非关键业务被关键业务所依赖，会导致非关键业务变成一个关键业务。
- 服务依赖链中，出现“木桶短板效应”——整个 SLA 由最差的那个服务所决定。
注意：
很多分布式架构在应用层上做到了业务隔离，然而，在数据库结点上并没有。如果一个非关键业务把数据库拖死，那么会导致全站不可用。
—— 最好一个业务线用一套自己的数据库。
—— 系统间不能读取对方的数据库，只通过服务接口耦合。

#### 问题三：故障发生的概率更大
出现故障不可怕，故障恢复时间过长、或者故障影响面过大才可怕。
“防火胜于救火”，我们还要考虑如何防火，这需要我们在设计或运维系统时都要为这些故障考虑，即所谓 Design for Failure。在设计时就要考虑如何减轻故障。如果无法避免，也要使用自动化的方式恢复故障，减少故障影响面。
人管代码，代码管机器，人不管机器！

#### 问题四：多层架构的运维复杂度更大
很多公司都是按技能分工的
  ——  没有统一的视图和管理，导致运维被割裂开来，造成更大的复杂度。
分工不是问题，问题是分工后的协作是否统一和规范。


## 23 分布式系统的技术栈
构建分布式系统的目的是增加系统容量，提高系统的可用性，即完成：
- 大流量处理。
- 关键业务保护。

### 提高架构性能
- 缓存系统。
- 负载均衡系统。
- 异步调用。
- 数据分区和数据镜像。

### 提高架构的稳定性
- 服务拆分。
- 服务冗余。
- 限流降级。
- 高可用运维。

### 分布式系统的关键技术
- 服务治理。
- 架构软件管理。
- DevOps。
- 自动化运维。
- 资源调度管理。
- 整体架构监控。
- 流量控制。

### 分布式系统的“纲”
- 全栈系统监控；
- 服务 / 资源调度；
- 流量调度；
- 状态 / 数据调度；
- 开发和运维的自动化。


## 25 分布式系统关键技术：服务调度
关键点：
服务关键程度
服务依赖关系
服务发现
整个架构的版本管理
服务应用生命周期全管理

## 流量与数据调度
流量调度关键技术：
- 高性能
- 扛流量
- 业务逻辑
- 服务化

以上4个特性，其实主要是在说API网关应该具备的特点。

#### 分布式事务一致性问题
数据副本是分布式解决数据丢失异常的唯一解决手段。
解决方案：
- Master/Slave
- Master/Master
- 两阶段与三阶段提交方案
- Paxos方案

应用层解决事务问题：两阶段提交
数据层解决事务问题：Paxos算法


## 27 洞悉PaaS平台的本质
首先还是抛出问题吧：
**为了构建一个分布式系统，我们面临的主要问题有:**
- 故障是常态，需要运维流程自动化
- 良好的服务设计，避免单点故障
- 容量的可伸缩性
- 老的服务可能是异构的，需要让它们使用标准化的协议
- 分布式存储使得事务处理变得复杂，事务无法自动恢复时，手工恢复将会很复杂
- 测试和查错的复杂度增大
- 系统吞度量会变大，但同时响应时间会变长

为了解决这些问题，了解了如下解决方案：
- 完善的监控系统
- 设计服务时要分析其依赖链
- 重构老的软件，使其服务化
- 为老的服务编写接口逻辑，以便使用标准协议，或必要时重构老的服务
- 自动构建服务的依赖地图
- 使用API网关
- 事务处理建议在存储层实现；根据业务需求，或是降级使用更简单、吞吐量更大的最终一致性方案，或是通过二阶段提交、paxos、raft、NWR等方案之一，使用吞吐量小的强一致性方案
- 异步调用；关键服务采用专属硬件资源，优化软件逻辑
  

## 41 弹力设计篇之“认识故障和弹力设计”
分布式系统中，可能出现多种问题，不出现故障基本不可能，需要考虑出现故障时如何尽快修复故障。
可能出现的故障主要有：
- 网络问题
- 性能问题
- 安全问题
- 运维问题
- 管理问题
- 硬件问题
  
故障不可避免，就需要**把处理故障的代码当成正常的功能做在架构里写在代码里**

左耳朵耗子叔这里说的弹力设计 Resiliency 主要是指：
- 好的情况下，系统出现故障后，能够自动修复，不需要人为介入
- 如果修复不了，系统能够自我保护，不让事态变得更糟

## 42 弹力设计篇之“隔离设计”
隔离设计所要解决的问题：发生故障时使故障隔离，不要导致系统整体不可用，减小影响范围
分离的方式：
- 以服务的种类来做分离
  - 异步处理，两阶段提交
- 以用户的请求来做分离
  - 多租户架构

## 43 弹力设计篇之“异步通讯设计”
系统间通讯，主要有2种：同步，异步

同步调用的问题：
- 整个同步调用链的性能会由最慢的那个服务所决定。
- 同步调用会导致调用方一直在等待被调用方完成，如果一层接一层地同步调用下去，所有的参与方会有相同的等待时间。高并发场景下，非常消耗资源。
- 同步调用只能是一对一的，很难做到一对多。
- 被调用方失败，调用方也会跟着失败，故障蔓延

异步通讯的方式：
- 1. 请求响应式
  - 又分为：发送方定期查询接收方是否完成，以及发送方注册回调、接收方完成后掉回调这两种。
- 2. 通过订阅的方式
  - 发送方发送事件，事件驱动
  - 缺点：接收方依赖于发送方，还是有耦合
- 3. 通过 Broker 的方式
  - 同样依赖于事件，但发送方、接收方都使用broker通信
  - 2和3都是**事件驱动设计**

### 事件驱动
- 优点
  - 消除了服务间依赖，每个服务都是高度可重用并可被替换的。
  - 开发、测试、运维，以及故障处理都是高度隔离的
  - 服务间是不会相互 block 的
  - 服务间增加一些 Adapter（如日志、认证、版本、限流、降级、熔断等）相当容易。
  - 服务间的吞吐也被解开了，各个服务可以按照自己的处理速度处理。
- 缺点
  - 业务流程不再那么明显和好管理。整个架构变得比较复杂
  - 事件可能会乱序。
  - 事务处理变得复杂。需要使用两阶段提交来做强一致性，或是退缩到最终一致性。

### 异步通讯
- 为何要异步通讯？
  - 解耦服务间的依赖
  - 让各个服务的隔离性更好，避免出故障时故障蔓延
  - 可以获得更大的吞吐量，而且各个服务间的性能不受干扰相对独立
  - 利用 Broker 或队列的方式还可以达到把抖动的吞吐量变成均匀的吞吐量，这就是所谓的“削峰”，这对后端系统是个不错的保护。
  - 部署、扩容和运维上都可以做到独立不受其他服务的干扰。
- 注意事项：
- 用于异步通讯的中间件 Broker需要设计成高可用不丢消息的；消息无法保证顺序，架构设计不要依赖于消息的顺序
- 业务处理流程不那么直观，在 Broker 上需要有相关的服务消息跟踪机制
- 业务状态最好由一个总控方来管理，用于维护一个业务流程的状态变迁逻辑，便于发生故障时查找问题、以及故障恢复
- 若消息可能重传，需要处理方有幂等的处理

## 44 弹力设计篇之“幂等性设计”
保证幂等性的几种方式：
- 需要有**全局ID**
  - SnowFlake算法
  - 数据库实现
  - Redis/MongoDB实现
  以上算法大同小异
- 处理流程
  - 实际执行操作时查询一下？
    - 有问题，多数情况不会发生重复，导致很多操作都是白费力，消耗资源
  - 使用id，保存时如果有重复直接抛错

HTTP的幂等性
- PRG模式


## 45 弹力设计篇之“服务的状态”
### 无状态的服务 stateless
- 为了做成无状态服务，可能依赖于导致这些服务需要耦合第三方有状态的存储服务
    - 比如，不太重要的数据可以放到 Redis 中，重要的数据可以放到 MySQL 中，或是像 ZooKeeper/Etcd 这样的高可用的强一致性的存储中，或是分布式文件系统中。
    - 要求这些存储服务也做成高可用高扩展的方式

### 有状态的服务 stateful
- 数据本地化（Data Locality）
  - 有更低的延时，而且对于数据密集型的应用来说，这会更快。
- 更高的可用性和更强的一致性
  - CAP 原理中的 A 和 C
  - 因为对于有状态的服务，我们需要对于客户端传来的请求，都必需保证其落在同一个实例上，这叫 Sticky Session 或是 Sticky Connection。这样一来，我们完全不需要考虑数据要被加载到不同的结点上去，而且这样的模型更容易理解和实现。
  - Sticky Session
    - 实现方式：
      - 持久化的长连
      - 哈希（hash）算法：uid取模，或是一致性hash
    - 问题：结点的负载和数据并不会很均匀
      - 解决：
        - 有一个元数据索引来映射后端服务实例和请求的对应关键，还需要一个路由结点
        - 使用到 Gossip 协议

### 服务状态的容错设计
一种方式：采取数据在运行时就复制的方案

## 46 弹力设计篇之“补偿事务”
CAP 理论：在分布式的服务架构中，一致性（Consistency）、可用性（Availability）、分区容忍性（Partition Tolerance），在现实中不能都满足，最多只能满足其中两个。

ACID 的一个变种 BASE：
- Basic Availability：基本可用。系统可以出现暂时不可用的状态，而后面会快速恢复。
- Soft-state：为了提高性能，我们可以让服务暂时保存一些状态或数据，这些状态和数据不是强一致性的。
- Eventual Consistency：最终一致性

ACID强调的是一致性（CAP中的C），BASE强调的是可用性（CAP中的A）

业务补偿机制需要做到：
- 清楚地描述出要达到什么样的状态，以及如果其中的条件不满足，那么，我们要回退到哪一个状态。
- 当整条业务跑起来的时候，我们可以串行或并行地做这些事。
  - 如果达不到，就需要通过补偿机制回滚到之前的状态。这就是所谓的状态拟合。
- 对于已经完成的事务进行整体修改，可以考虑成一个修改事务。

业务补偿机制设计重点：
- 服务方支持幂等性，上游有重试机制
- 最好是一个业务流程的控制方来做这个事，也就是一个工作流引擎。
- 补偿的业务逻辑和流程不一定非得是严格反向操作。有时候可以并行，有时候，可能会更简单。总之，设计业务正向流程的时候，也需要设计业务的反向补偿流程。
- 
- 下层的业务方最好提供短期的资源预留机制。


## 47 弹力设计篇之“重试设计”
### 重试的场景
并不是所有故障都要重试，故障是暂时的、不是永久的，才有必要重试。
例如：调用超时，被调用端返回了某种可以重试的错误（如繁忙中、流控中、维护中、资源不足等）。

不要重试：业务级的错误（如没有权限、或是非法数据等错误），技术上的错误

### 重试的策略
Exponential Backoff 指数级退避：每一次重试所需要的休息时间都会成倍增加

### Spring的重试策略
- Spring Retry项目

### 重试设计的重点
- 要确定什么样的错误下需要重试
- 重试的时间和重试的次数
- 如果超过重试次数，或是一段时间，那么重试就没有意义了。
- 重试还需要考虑被调用方是否有幂等的设计
- 重试的代码比较简单也比较通用，完全可以不用侵入到业务代码中。
- 留意有事务相关的操作


## 48 弹力设计篇之“熔断设计”
### 熔断设计
可以使用状态机来实现，内部模拟以下状态：
- 闭合（close）
- 断开（open）： 在该状态下，对应用程序的请求会立即返回错误响应，而不调用后端的服务。
- 半开（half-open）允许应用程序一定数量的请求去调用服务，根据这些请求的调用情况来决定后续是切换为断开状态还是闭合状态。

### 熔断设计重点
- 错误的类型
- 日志的监控
- 测试服务是否可用
- 手动重置
- 并发问题
- 资源分区
- 重试错误的请求

## 49 弹力设计篇之“限流设计”
保护系统不会在过载的情况下出现问题，就需要限流。
### 限流的策略
- 拒绝服务
- 服务降级
  - 关停不重要的服务
  - 不再返回全量数据，只返回部分
- 特权请求
  - 资源不够时，有限的资源分给重要的客户
- 延时处理
  - 如：使用队列缓冲请求
- 弹性伸缩
  - 动用自动化运维的方式对相应的服务做自动化的伸缩。
    - 当然，如果是数据库的压力过大，弹性伸缩应用是没什么用的，这个时候还是应该限流。

### 限流的实现方式
- 计数器方式
- 队列算法
  - 变种：
    - 高/低优先级队列
    - 为避免饿死：权重队列
- 漏斗算法 Leaky Bucket
  - 经常用队列实现
  - 处理请求是以一个常量和恒定的速度处理的
- 令牌桶算法 Token Bucket
  - 令牌桶算法则是在流量小的时候“攒钱”，流量大的时候，可以快速处理。
- 基于响应时间的动态限流
  - 典型：TCP协议的拥塞控制的算法 Round Trip Time
    - **需要仔细研究下这个部分**

### 限流的设计要点
- 在架构的早期考虑
- 限流模块性能必须好，而且对流量的变化也是非常灵敏的
- 限流应该有个手动的开关，这样在应急的时候，可以手动操作
- 当限流发生时，应该有个监控事件通知。
- 当限流发生时，对于拒掉的请求，我们应该返回一个特定的限流错误码。
- 限流应该让后端的服务感知到。

## 50 弹力设计篇之“降级设计”
降级设计（Degradation）
降级时，一般会牺牲掉：
- 降低一致性：从强一致性变成最终一致性
  - 使用异步简化流程
  - 降低数据的一致性
    - 缓存，或是去掉数据
- 停止次要功能：
- 简化功能

### 降级设计要点
在设计降级的时候，需要清楚地定义好降级的关键条件，如吞吐量过大、响应时间过慢、失败次数多过，有网络或是服务故障，等等，然后做好相应的应急预案。这些预案最好是写成代码可以快速地自动化或半自动化执行的。

### 参考文章
-[缓存更新的套路]
