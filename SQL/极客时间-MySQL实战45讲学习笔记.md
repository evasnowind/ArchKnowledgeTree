# 极客时间-MySQL实战45讲学习笔记

[TOC]

## 01 | 基础架构：一条SQL查询语句是如何执行的？

SQL执行示例
```
mysql> select * from T where ID=10；
```

MySQL分为：
- Server层
  - 包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。
- 存储引擎
  - 插件式设计，常见：InnoDB, MyISAM, Memory
  - 从5.5 开始默认为InnoDB
  - create table时可以指定存储引擎


### 连接器
查看当前已创建的连接：
```
show processlist
```
客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数 wait_timeout 控制的，默认值是 8 小时。

数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。
建立连接的过程通常是比较复杂的，所以我建议你在使用中要尽量减少建立连接的动作，也就是尽量使用长连接。

但全部使用长连接后，你可能会发现，有些时候 MySQL 占用内存涨得特别快
——MySQL 在执行过程中临时使用的内存是管理在连接对象里面的，连接断开时才会释放。如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是 MySQL 异常重启了。

解决长连接导致OOM、继而导致MySQL异常重启的方法：
- 定期断开长连接。
- 如果你用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。


### 查询缓存
大多数情况下我会建议你不要使用查询缓存，因为查询缓存往往弊大于利。
查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。除非你的业务就是有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。
MySQL 也提供了这种“按需使用”的方式。你可以将参数 query_cache_type 设置成 DEMAND，这样对于默认的 SQL 语句都不使用查询缓存。而对于你确定要使用查询缓存的语句，可以用 SQL_CACHE 显式指定，像下面这个语句一样：

```
mysql> select SQL_CACHE * from T where ID=10；
```
8.0 开始彻底没有查询缓存功能。

### 分析器
### 优化器
### 执行器
在数据库的慢查询日志中看到一个 rows_examined 的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟 rows_examined 并不是完全相同的。


## 02 | 日志系统：一条SQL更新语句是如何执行的？
在一个表上有更新的时候，跟这个表有关的查询缓存会失效，所以这条语句就会把表 T 上所有缓存结果都清空。

### redo log 重做日志
**WAL 技术**：Write-Ahead Logging，先写日志，再写磁盘
InnoDB 引擎就会先把记录写到 redo log，更新内存，然后在适当的时候（系统较为空闲时）更新磁盘记录。
InnoDB 的 redo log 是固定大小的，结构如下图：
![02-redo-log.png](images/02-redo-log.png)
redo log保证了InnoDB存储引擎在发生异常、重启时，之前提交的记录不会丢失——crash-safe能力

### binlog 归档日志
MySQL的结构:
- server层
  - binlog，只用于归档
- 存储引擎层
  - MySQL 自带的引擎是 MyISAM没有redo log，InnoDB是以插件形式集成进来，InnoDB自己为保证crash-safe才实现了redo log

binlog与redo log区别：
- redo log是InnoDB特有，binlog在MySQL server层，所有引擎可用
- redo log是物理日志，binlog是逻辑日志
- redo log循环写入，binlog追加写入

Redo log不是记录数据页“更新之后的状态”，而是记录这个页 “做了什么改动”。
Binlog有两种模式，statement 格式的话是记sql语句， row格式会记录行的内容，记两条，更新前和更新后都有。

### binlog不能去掉
- redo log只有InnoDB有，别的引擎没有。
- redolog是循环写的，不持久保存，binlog的“归档”这个功能，redolog是不具备的。

其核心就是， redo log 记录的，即使异常重启，都会刷新到磁盘，而 bin log 记录的， 则主要用于备份。

### 为什么日志需要“两阶段提交”
redo log 和 binlog 都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。

## 03 | 事务隔离：为什么你改了我还看不见？

### 隔离性与隔离级别
ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性）

多个事务同时执行，可能出现：
脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）的问题
——隔离级别

SQL 标准的事务隔离级别包括：
- 读未提交（read uncommitted）
- 读提交（read committed）
- 可重复读（repeatable read）
  - 事务在执行期间看到的数据前后必须是一致的
- 串行化（serializable ）
隔离级别越高，效率越低，需要权衡。

Oracle 数据库的默认隔离级别是“读提交”
MySQL默认隔离级别是“可重复读”
——从Oracle迁移到MySQL，为保证数据库隔离级别的一致，你一定要记得将 MySQL 的隔离级别设置为“读提交”，即将启动参数 transaction-isolation 的值设置成 READ-COMMITTED
查看方式：
```
show variables like 'transaction_isolation';
```
### 事务隔离的实现

为何建议尽量不使用长事务？
- 对回滚段的影响
- 占用锁资源
- 可能拖垮整个库

参考文章：[MySQL-长事务详解](https://www.cnblogs.com/kunjian/p/11552646.html)


### 事务的启动方式
MySQL 的事务启动方式有以下几种：
1. 显式启动：begin 或 start transaction。配套的提交语句是 commit，回滚语句是 rollback。
2. set autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。

建议总是使用 set autocommit=1, 通过显式语句的方式来启动事务。

若纠结“多一次交互”的问题，希望减少交互次数，则建议使用**commit work and chain 语法**

可以在 information_schema 库的 innodb_trx 这个表中查询长事务
如下面这个语句，用于查找持续时间超过 60s 的事务：
```
select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60
```

### 参考资料
- [MySQL-长事务详解](https://www.cnblogs.com/kunjian/p/11552646.html)


## 04 | 深入浅出索引（上）
### 索引的常见模型：
- 哈希表：适用于只有等值查询的场景，比如 Memcached 及其他一些 NoSQL 引擎。
- 有序数组：在等值查询和范围查询场景中的性能就都非常优秀，只适用于静态存储引擎
- N 叉树
- 其他：跳表、LSM 树等

### InnoDB 的索引模型
B+ 树
根据叶子节点的内容，索引类型分为：主键索引和非主键索引
主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）。
非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引（secondary index）。
基于主键索引和普通索引的查询有什么区别？
——基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。

### 索引维护
选择自增字段作为主键，还是采用业务字段作为主键？
主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。从性能和存储空间方面考量，自增主键往往是更合理的选择。

有些业务的场景需求是这样的：只有一个索引，且该索引必须是唯一索引（KV场景）
——没有其他索引，不用考虑其他索引叶子节点大小问题，直接用业务字段即可。



## 05 | 深入浅出索引（下）
回到主键索引树搜索的过程，我们称为回表

### 覆盖索引
```
select * from T where k between 3 and 5
```
需要回表。

```
select ID from T where k between 3 and 5
```
覆盖索引
**由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。**

应用：
市民信息表中有姓名、身份证号字段：
针对利用身份证号查询市民信息：索引仅建在身份证号即可
若有利用身份证号查姓名的高频需求：额外创建（身份证号、姓名）的联合索引，避免回表，直接覆盖索引

### 最左前缀原则
**在建立联合索引的时候，如何安排索引内的字段顺序。**
评估标准是，索引的复用能力
- **第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的**
  - 当已经有了 (a,b) 这个联合索引后，一般就不需要单独在 a 上建立索引了
- 索引占用空间

### 索引下推
MySQL 5.6 引入索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。


## 06 | 全局锁和表锁 ：给表加个字段怎么有这么多阻碍？
根据加锁的范围，MySQL 里面的锁大致可以分成全局锁、表级锁和行锁三类。

### 全局锁
全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)。

**全局锁的典型使用场景是，做全库逻辑备份。**也就是把整库每个表都 select 出来存成文本。
——另一种思路：如果是InnoDB这种支持事务的引擎，可以在可重复读隔离级别下开启一个事务，以便保证备份过程中看到的是一致性视图。MyISAM不支持事务，只能用FTWRL了。

官方自带的逻辑备份工具是 mysqldump。当 **mysqldump** 使用参数**–single-transaction** 的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。
——single-transaction 方法只适用于所有的表使用事务引擎的库。

既然要全库只读，为什么不使用 set global readonly=true 的方式呢？
- 在有些系统中，readonly 的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。
- 在异常处理机制上有差异。

### 表级锁
MySQL 里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。
表锁的语法是 lock tables … read/write。
需要注意，lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。

另一类表级的锁是 MDL（metadata lock)。
MDL 不需要显式使用，在访问一个表的时候会被自动加上：读锁之间不互斥，读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。

事务中的 MDL 锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放。

**问题：如何安全地给小表加字段？**

## 07 | 行锁功过：怎么减少行锁对性能的影响？
MySQL 的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁
**在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。**
——如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。

### 死锁和死锁检测
数据库死锁时，有两种策略：
- 直接进入等待，直至超过超时时间。超时时间配置innodb_lock_wait_timeout。默认值为50s。
- 发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务.参数 innodb_deadlock_detect 设置为 on 则表示开启死锁检测。

怎么解决由这种热点行更新导致的性能问题呢？
——死锁检测要耗费大量的 CPU 资源

## 08 | 事务到底是隔离的还是不隔离的？
事务的启动时机：begin/start transaction 命令并不是一个事务的起点，在执行到它们之后的第一个操作 InnoDB 表的语句，事务才真正启动。如果你想要马上启动一个事务，可以使用 start transaction with consistent snapshot 这个命令。

InnoDB 利用了“所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能力。

一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况：
- 版本未提交，不可见；
- 版本已提交，但是是在视图创建后提交的，不可见；
- 版本已提交，而且是在视图创建前提交的，可见。

**更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。**

除了 update 语句外，select 语句如果加锁，也是当前读。如：查询语句 select * from t where id=1 加上 lock in share mode 或 for update，下面这两个 select 语句，就是分别加了读锁（S 锁，共享锁）和写锁（X 锁，排他锁）。
```
mysql> select k from t where id=1 lock in share mode;
mysql> select k from t where id=1 for update;
```

### 事务的可重复读的能力是怎么实现的？
可重复读的核心就是一致性读（consistent read）；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。

InnoDB 的行数据有多个版本，每个数据版本有自己的 row trx_id，每个事务或者语句有自己的一致性视图。普通查询语句是一致性读，一致性读会根据 row trx_id 和一致性视图确定数据版本的可见性。对于可重复读，查询只承认在事务启动前就已经提交完成的数据；对于读提交，查询只承认在语句启动前就已经提交完成的数据；而当前读，总是读取已经提交完成的最新版本。

## 09 | 普通索引和唯一索引，应该怎么选择？
### 查询过程
- 对于普通索引来说，查找到满足条件的第一个记录 (5,500) 后，需要查找下一个记录，直到碰到第一个不满足 k=5 条件的记录。
- 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。
上述区别带来的性能差距微乎其微。

### 更新过程
**change buffer**：当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。

change buffer 在内存中有拷贝，也会被写入到磁盘上。

将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge。除了访问这个数据页会触发 merge 外，系统有后台线程会定期 merge。在数据库正常关闭（shutdown）的过程中，也会执行 merge 操作。

**什么条件下可以使用 change buffer 呢？**
对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。
唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以使用。

change buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的大小，可以通过参数 innodb_change_buffer_max_size 来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。

例子：在表中插入一个新记录，InnoDB处理流程：
- 这个记录要更新的目标页在内存中：唯一索引查询到之后，需要判断是否唯一，多一次判断，其他操作和普通索引一致，因而性能差异很小。
- 这个记录要更新的目标页不在内存中：唯一索引需要将数据页写入内存，判断是否冲突，然后写入；普通索引将更新记录在 change buffer，语句执行就结束了。
将数据从磁盘读入内存涉及随机 IO 的访问，是数据库里面成本最高的操作之一。change buffer 因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。

**change buffer 的使用场景**
change buffer 只限于用在普通索引的场景下，而不适用于唯一索引。
因为 merge 的时候是真正进行数据更新的时刻，而 change buffer 的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做 merge 之前，change buffer 记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。

因此，对于写多读少的业务来说，change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。
反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 merge 过程。这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。所以，对于这种业务模式来说，change buffer 反而起到了副作用。

### 索引选择和实践
这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。所以，我建议你尽量选择普通索引。
如果所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭 change buffer。而在其他情况下，change buffer 都能提升更新性能。

如果要简单地对比这两个机制在提升更新性能上的收益的话，**redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗。**


## 10 | MySQL为什么有时候会选错索引？
### 优化器的逻辑
优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。
考虑因素：扫描行数，还会结合是否使用临时表、是否排序等因素进行综合判断。

**扫描行数是怎么判断的？**
一个索引上不同的值越多，这个索引的区分度就越好。而一个索引上不同的值的个数，我们称之为“基数”（cardinality）。也就是说，这个基数越大，索引的区分度越好。
```
show index from 表名;
```
该命令可以查看区分度（cardinality）

**MySQL 是怎样得到索引的基数的呢？**
采样统计，因而所计算基数并不准确
如：InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。而数据表是会持续更新的，索引统计信息也不会固定不变。所以，当变更的数据行数超过 1/M 的时候，会自动触发重新做一次索引统计。

存储索引统计的方式：持久化存储，或是只存在内存中。innodb_stats_persistent参数用于配置该方式。

如果是普通索引，在索引上查询到之后，还需要回到主键索引查出整行数据。
——这个代价优化器也要算进去，即：比较直接用主键索引进行查询的代价，与使用普通索引、然后回表的代价，两者相比较。

如果是统计基数有问题，可以用如下命令重新计算基数，然后再用explain看看是否有改善：
```
analyze table 表名
```
在实践中，如果你发现 explain 的结果预估的 rows 值跟实际情况差距比较大，可以采用这个方法来处理。

### 索引选择异常和处理
大多数时候优化器都能找到正确的索引，但偶尔你还是会碰到我们上面举例的这两种情况：原本可以执行得很快的 SQL 语句，执行速度却比你预期的慢很多，你应该怎么办呢？
- 方法1：采用 force index 强行选择一个索引
  - 需要改写代码，开发、测试、发布，代价较大
- 方法2：可以考虑修改语句，引导 MySQL 使用我们期望的索引
  - 例子：`select * from t where (a between 1 and 1000) and (b between 50000 and 100000) order by b limit 1;` 
  - 改写方法1：把“order by b limit 1” 改成 “order by b,a limit 1”
  - 改写方法2：`select * from  (select * from t where (a between 1 and 1000)  and (b between 50000 and 100000) order by b limit 100)alias limit 1;`
- 方法3：在有些场景下，我们可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。


## 11 | 怎么给字符串字段加索引？
问题：如何在邮箱这样的字段上加索引？

### 思路1：给邮箱整个字段加索引
### 思路2：使用邮箱前缀加索引

区别：
- 存储上，思路1占用空间大，但可以减少扫描次数；思路2，前缀占用空间少，可能重复，因而可能会导致更多的扫描次数
- 如果查询的是只是"物理id,邮箱地址"，那么思路1不用回表；思路2还是需要回表查询。
  - 此即前缀索引对覆盖索引的影响

**使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本。**
问题：如何确定前缀索引使用多长的前缀？
根据字段区分度，统计索引上有多少个不同的值来判断。

```
mysql> select 
  count(distinct left(email,4)）as L4,
  count(distinct left(email,5)）as L5,
  count(distinct left(email,6)）as L6,
  count(distinct left(email,7)）as L7,
from SUser;
```

当然，使用前缀索引很可能会损失区分度，所以你需要预先设定一个可以接受的损失比例，比如 5%。然后，在返回的 L4~L7 中，找出不小于 L * 95% 的值，假设这里 L6、L7 都满足，你就可以选择前缀长度为 6。


其他方式:
比如类似身份证号的字段，前缀有大量重复，可能是中间、或是后缀有区分度的情况

### 思路3：使用倒序存储
存储身份证号的时候把它倒过来存，查询时，这么查询：
```
mysql> select field_list from t where id_card = reverse('input_id_card_string');
```
注意，也要用count(distinct)的方式验证倒序后，采用前缀索引的区分度。

### 思路4：使用hash字段
可以在表上再创建一个整数字段，来保存身份证的校验码，同时在这个字段上创建索引。
```
mysql> alter table t add id_card_crc int unsigned, add index(id_card_crc);
```

每次插入新记录的时候，都同时用 crc32() 这个函数得到校验码填到这个新字段。
由于校验码可能存在冲突，查询语句 where 部分要判断 id_card 的值是否精确相同。即：
```
mysql> select field_list from t where id_card_crc=crc32('input_id_card_string') and id_card='input_id_card_string'
```

思路3、4都不支持范围索引，只支持等值查询；查询效率上，思路4使用hash的查询性能更稳定，因为hash冲突概率很小


## 12 | 为什么我的MySQL会“抖”一下？
当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。

**WAL技术**
Write-Ahead Logging，它的关键点就是先写日志，再写磁盘。InnoDB 引擎就会先把记录写到 redo log里面，并更新内存，这个时候更新就算完成了。
平时执行很快的更新操作，其实就是在写内存和日志，而 MySQL 偶尔“抖”一下的那个瞬间，可能就是在刷脏页（flush）。

### 什么情况会引发数据库的 flush 过程呢？
- 情况1：InnoDB 的 redo log 写满了。这时候系统会停止所有更新操作，把 checkpoint 往前推进，redo log 留出空间可以继续写。
- 情况2：系统内存不足。当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘。
- 情况3：MySQL 认为系统“空闲”的时候。
- 情况4：MySQL 正常关闭的情况。

情况3是空闲时候，不会影响业务，不用管；
情况4即将关闭肯定没有什么业务请求，不用管；
情况1会堵塞更新，需要尽量避免；
情况2是常态，InnoDB 用缓冲池（buffer pool）管理内存，缓冲池中的内存页有三种状态：
- 还没有使用
- 已使用，是干净页
- 已使用，是脏页
InnoDB 的策略是尽量使用内存，因此对于一个长时间运行的库来说，未被使用的页面很少。
出现以下这两种情况，都是会明显影响性能的：
1. 一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长；
2. 日志写满，更新全部堵住，写性能跌为 0，这种情况对敏感业务来说，是不能接受的。

所以，InnoDB 需要有控制脏页比例的机制，来尽量避免上面的这两种情况。

### InnoDB 刷脏页的控制策略
1. 首先需要告知InnoDB所在主机的IO能力
   配置innodb_io_capacity参数，建议设置为磁盘的IOPS。磁盘的IOPS可以用fio来测试。比如作者用以下语句测试随机读写性能：
   ```  
    fio -filename=$filename -direct=1 -iodepth 1 -thread -rw=randrw -ioengine=psync -bs=16k -size=500M -numjobs=10 -runtime=10 -group_reporting -name=mytest 
   ```
   innodb_io_capacity 参数配置错误，可能导致上不去。
2. 控制InnoDB刷脏页速度
   如果刷太慢，将导致：内存脏页太多，redo log写满
   要避免该情况，因而刷盘速度需要考虑：一个是脏页比例，一个是 redo log 写盘速度。
   参数 innodb_max_dirty_pages_pct 是脏页比例上限，默认值是 75%。
   ![InnoDB刷脏页速度策略](images/InnoDB刷脏页速度策略.png)

   无论是你的查询语句在需要内存的时候可能要求淘汰一个脏页，还是由于刷脏页的逻辑会占用 IO 资源并可能影响到了你的更新语句，都可能是造成你从业务端感知到 MySQL“抖”了一下的原因。

要尽量避免这种情况，你就要合理地设置 innodb_io_capacity 的值，并且平时要多关注脏页比例，不要让它经常接近 75%。
其中，脏页比例是通过 Innodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_total 得到的，具体的命令参考下面的代码：
```

mysql> select VARIABLE_VALUE into @a from global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_dirty';
select VARIABLE_VALUE into @b from global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_total';
select @a/@b;
```

MySQL 中有一个机制：在准备刷一个脏页的时候，如果这个数据页旁边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉；而且这个把“邻居”拖下水的逻辑还可以继续蔓延。
——可能导致刷脏页时查询更慢。
在 InnoDB 中，innodb_flush_neighbors 参数就是用来控制这个行为的，值为 1 的时候会有上述的“连坐”机制，值为 0 时表示不找邻居，自己刷自己的。
机械硬盘下这种机制可以减少随机IO，提高性能，建议设置为1；SSD则没必要，建议设置为0.MySQL 8中已经默认置为0.


## 13 | 为什么表数据删掉一半，表文件大小不变？
### 直接删除表数据无法减少占用空间的原因
表数据既可以存在共享表空间里，也可以是单独的文件。这个行为是由参数 innodb_file_per_table 控制的：
- OFF 表示的是，表的数据放在系统共享表空间，也就是跟数据字典放在一起；
- ON表示每个 InnoDB 表数据存储在一个以 .ibd 为后缀的文件中。

建议不论使用 MySQL 的哪个版本，都将这个值设置为 ON。
——一个表单独存一个文件更方便管理，并且drop table命令删除表时，ON的情况可以直接删除数据、回收空间，OFF则不会回收空间。

将 innodb_file_per_table 设置为 ON，是推荐做法，以下都是基于该设置展开。
在删除整个表的时候，可以使用 drop table 命令回收表空间。但有些时候并不是删除所有、只删除某些行，此时会遇到：
**表中的数据被删除了，但是表空间却没有被回收。**

原因1：删除（delete）操作造成数据“空洞”。以InnoDB为例，存储采用B+树，删除时只是标记为可复用、数据并未真正被删除。
InnoDB按页存储数据，若删除某页上的所有数据，则整个数据页可以复用、但同样没有被真正删除。
原因2：插入操作同样会造成数据“空洞”。B+树，新增数据，可能造成叶子分裂，分裂后可能有空洞。
原因3：更新操作同样会造成数据“空洞”。更新相当于删除一个旧值、插入一个新值。同原因1、2所解释。

### 收缩表空间的操作：重建表
重建表可以减少减少空洞、回收空间。
可以应用`alter table A engine=InnoDB`命令来重建表。在** MySQL 5.5 版本**之前，这个命令会自动完成转存数据、交换表名、删除旧表的操作。
注意：花时间最多的步骤是往临时表插入数据的过程，该过程中原始表不能有更新，否则可能就存在数据丢失。即DDL操作是离线的。

**MySQL 5.6 版本开始引入的 Online DDL，对这个操作流程做了优化。**：`alter table A engine=InnoDB`命令，对于一个大表来说，Online DDL 最耗时的过程就是拷贝数据到临时表的过程，这个步骤的执行期间可以接受增删改操作。因而算做Online的。
——由于扫描原表、构建临时文件很消耗CPU和IO，需要控制操作时间。推荐采用使用 GitHub 开源的 gh-ost 来做。

### Online和inplace
Online DDL做法，等价于：
```
alter table t engine=innodb,ALGORITHM=inplace;
```
即** MySQL 5.5 版本**之后的版本`alter table A engine=InnoDB`命令在InnoDB内部创建临时文件，在mysql server层没有感知。

另一种则是：
```
alter table t engine=innodb,ALGORITHM=copy;
```
copy即强制拷贝表，即** MySQL 5.5 版本**之前`alter table A engine=InnoDB`命令的实现，即在mysql server层创建表。


## 14 | count(*)这么慢，我该怎么办？
### count(*) 的实现方式
在不同的 MySQL 引擎中，count(*) 有不同的实现方式：
- MyISAM：把一个表的总行数存在了磁盘上，count(*)直接返回这个总行数，效率高
- InnoDB：执行 count(*)时，一行行扫描，累积计数
——上述说的是没有过滤条件的count(*)。加where后MyISAM也要扫描很多行。

**为什么 InnoDB 不跟 MyISAM 一样，也把数字存起来呢？**
这和 InnoDB 的事务设计有关系，可重复读是它默认的隔离级别，在代码上就是通过多版本并发控制，也就是 MVCC 来实现的。每一行记录都要判断自己是否对这个会话可见，因此对于 count(*) 请求来说，InnoDB 只好把数据一行一行地读出依次判断，可见的行才能够用于计算“基于这个查询”的表的总行数。

**在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。**

- MyISAM 表虽然 count(*) 很快，但是不支持事务；
- show table status 命令虽然返回很快，但是不准确；
- InnoDB 表直接 count(*) 会遍历全表，虽然结果准确，但会导致性能问题。

### 用缓存系统保存计数
将计数保存在缓存系统中的方式，还不只是丢失更新的问题。即使 Redis 正常工作，这个值还是逻辑上不精确的。因为：这两个不同的存储构成的系统，不支持分布式事务，无法拿到精确一致的视图。
因此，需要将计数保存到数据库里，利用数据库事务保证多个操作数据的一致性。

### 不同的 count 用法
按照效率排序的话，`count(字段)<count(主键 id)<count(1)≈count(*)`，所以建议尽量使用 count(*)。



## 19 | 为什么我只查一行的语句，也执行这么慢？
### 第一类：查询长时间不返回
- 等 MDL 锁
- 等 flush
- 等行锁

### 第二类：查询慢
**坏查询不一定是慢查询。**